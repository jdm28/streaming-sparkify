# Project data modeling with PostgreSQL.

### The purpose.

The purpose is to create an ETL that allows you to process the data with Spark and store the result in an s3 bucket. This will allow your analytics team to continue to find information about the songs your users are listening to.

### Data.

***Song datasets***: This set contains the musics and artists. A sample of this files is:
```
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```

***Log datasets***: contains the events generated by the users. A sample of a single row of each files is:
```
{"artist":"Sydney Youngblood","auth":"Logged In","firstName":"Jacob","gender":"M","itemInSession":53,"lastName":"Klein","length":238.07955,"level":"paid","location":"Tampa-St. Petersburg-Clearwater, FL","method":"PUT","page":"NextSong","registration":1540558108796.0,"sessionId":954,"song":"Ain't No Sunshine","status":200,"ts":1543449657796,"userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.78.2 (KHTML, like Gecko) Version\/7.0.6 Safari\/537.78.2\"","userId":"73"}
```

## Project structure

Project files:

* ***data***: Directory containing the files with data.

* ***dl.cfg***: Etl configuration file.

* ***etl.py***: This file contains the process responsible for extracting the data from the udacity S3 bucket. And with Spark we generate a new result that we write to our s3 bucket.

* ***README.md***: This file contains the description of the project.

### Prerequisites
* Pyspark   2.4.3
* Aws credentials 
* Create an S3 bucket

### Installing.

1. Set the variables in the dl.cfg.
* ***AWS_ACCESS_KEY_ID***: Aws access key 
* ***AWS_SECRET_ACCESS_KEY***: Aws secret key 
* ***OUTPUT_DATA***: Bucket s3 output

2. Execute the following command to perform the ingestion.

> `python etl.py; echo $?`

***If the program ends with 0 it was executed correctly.***

## Running the tests

Validate in the bucket containing parquet files.

## Authors

* **Jose Marquez** - [Github](https://github.com/jmarquez42)

